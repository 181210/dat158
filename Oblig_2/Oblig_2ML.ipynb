{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dogs vs. Cats Redux: Kernels Edition** \n",
    "##### K. Neteland - 181210\n",
    "\n",
    "<img src=\"img/dog_vs_cat.jpg\" width=\"620\" height=\"351\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In 2013 Kaggle hosted the original dogs versus cats challenge as a for-fun competition. Rumour has it that the lack of an online coding environment lead to approached sharing by scratching primitive glpyhs on cave walls with sticks and sharp objects. Now the classification problem is reintroduced back on Kaggle as a playground competition with kernels enabled. Although modern techniques may make light of this once-difficult problem, it is through practice of new techniques on old datasets that we will make light of machine learning's future challenges.\n",
    "\n",
    "##### The rule is simple: The train folder contains 25,000 images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains 12,500 images, named according to a numeric id. For each image in the test set, you should predict a probability that the image is a dog (1 = dog, 0 = cat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **References**\n",
    "\n",
    "* ##### __[Kaggle](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)__ - Source for discussion on data and solutions presented. \n",
    "* ##### __[CNN in Keras](https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/)__ - Image Classification using Convolutional Neural Networks in Keras.\n",
    "* ##### __[Kears](https://keras.io/)__ - Keras documentation.\n",
    "* ##### __[Images and Pixels](https://processing.org/tutorials/pixels/)__ - from the book Learning Processing by Daniel Shiffman.\n",
    "\n",
    "* ##### TBN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Strategies**\n",
    "\n",
    "##### From the information given on Kaggle I already have a great deal of knowledge about the data set. The data is pre-divided into a test set of 12 500 images and a training set of 25 000 images equally separated into pictures of dogs and cats. The content of the data is fitting for a classification project, which is also the reason why I chose this particular set since the last assignment was a regression problem. I am curious to work with a different set of tools, learn about CNNs and deep learning in general. \n",
    "\n",
    "<img src=\"img/ml_map.png\" width=\"2122\" height=\"1323\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following the flow chart taken from __[scikit-learn](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html?fbclid=IwAR0hJnqIJpjQMpINaXUY1_PHAu0e4TUmQ8WHDbWLj9Ky2SO7VpKxLLcK6rw)__ my data set falls into the Support Vector Machines/Ensemble Classifiers subset within Classification problems. As mentioned earlier this data-set was released on Kaggle in 2013 and was concidered a great challenge at the time given the methods that were available. Since then alot has changed in the world of AI with deep learning models, for example re-introducing the neural network but with more layers, and more powerful hardware that lets us computate bigger data-sets which again can lead to more precise models. The DAT158 course gave a quick introduction to Deep Learning without going into too much details about implementation and different frameworks available so to understand the bigger picture of the project I've made a list of components that I need to understand in order to get the results I'm aming for.  \n",
    "\n",
    "* ##### 1 - Images. How are they constructed?\n",
    "\n",
    "    * ##### \"A digital image is nothing more than data—numbers indicating variations of red, green, and blue at a particular location on a grid of pixels. Most of the time, we view these pixels as miniature rectangles sandwiched together on a computer screen. With a little creative thinking and some lower level manipulation of pixels with code, however, we can display that information in a myriad of ways.\" - Daniel Shiffman\n",
    "    \n",
    "    RBG   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "* ##### 2 - Feature extractions. How does it work?\n",
    "* ##### 3 - Feature vectors. What are they used for?\n",
    "* ##### 4 - Convolutional Neural Networks. How are they working?\n",
    "* ##### 5 - TensorFlow. What does it do?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prerequisitions**\n",
    "\n",
    "##### **Technologies:**\n",
    "##### Deep Learning/CNN: Keras, TensorFlow ....TODO\n",
    "##### **HW:**\n",
    "##### GPU --> __[GTX 1080Ti](https://developer.nvidia.com/cuda-gpus)__\n",
    "##### CPU --> Intel i7 7700k\n",
    "##### RAM --> 16GB 3200MHz \n",
    "##### **Environments:**\n",
    "##### __[CUDA 9.2](https://docs.nvidia.com/cuda/archive/9.2/)__\n",
    "##### __[Nvidia Docker](https://github.com/NVIDIA/nvidia-docker)__\n",
    "##### __[Docker ML Environment](https://github.com/181192/P030-MLDockerEnv)__\n",
    "##### **DATA:**\n",
    "##### __[Dataset](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data)__\n",
    "##### Layers of a picture, quality, size, how images are processed. https://processing.org/tutorials/pixels/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO - Import all libs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import data from folder, divide into test/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Gain insights**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Look at the data to gain understanding. Image size matters? RGB or less layers for easier processing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the data for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Select model and train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare the CNN in Keras -> TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fine tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tune hyperparameters, loss function, back propagation, look at and evaluate the outcome of the model -> overfitting? Less layers? Max Pooling? ect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Present solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Submissions are scored on the log loss:\n",
    "\n",
    "##### LogLoss=−1n∑i=1n[yilog(y^i)+(1−yi)log(1−y^i)],\n",
    "\n",
    "##### where\n",
    "\n",
    "* #####    n     : is the number of images in the test set\n",
    "* #####    y^i   : is the predicted probability of the image being a dog\n",
    "* #####    yi    : is 1 if the image is a dog, 0 if cat\n",
    "* #####    log() : is the natural (base e) logarithm\n",
    "\n",
    "##### A smaller log loss is better.\n",
    "\n",
    "##### For each image in the test set, you must submit a probability that image is a dog. The file should have a header and be in the following format:\n",
    "\n",
    "##### id,label\n",
    "##### 1,0.5\n",
    "##### 2,0.5\n",
    "##### 3,0.5\n",
    "##### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This model is based on binary classification of dog and cat images. Transferred learning to another binary classification project could be applicable. The obvious weakness is that if the model is presented with a photo that is not of either a dog or a cat its limitation would classify it as one or another due to the architecture of the network. If it's not a dog, it's a cat and vice verca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
